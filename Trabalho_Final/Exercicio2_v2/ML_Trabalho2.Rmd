---
title: "Modelos de IA e ML"
authors: "Alex Dias, Andre Rodrigues, Jose Cruz, Paulo Araujo"
subtitle: Trabalho 2
output:
   html_document:
      toc: yes
      theme: cosmo
      highlight: tango
      # code_folding: hide
      fig_width: 12
      fig_height: 8
runtime: shiny
params:
  d: !r Sys.Date()
---

![](https://i.ibb.co/mXvdH3h/Fiap-logo-novo.jpg){ width=20% }

##### Today's date is `r params$d`

```{r setup, include=FALSE}
knitr::opts_chunk$set(
                      # fig.width=12, 
                      # fig.height=8, 
                      echo = TRUE, 
                      error = TRUE, 
                      warning=FALSE, 
                      message=FALSE
                      )
rm(list = ls())
library(plotly)
library(stargazer)
```

******

<!-- 1- Não tem target porque é um problema de aprendizagem não-supervisionado -->
<!-- 2- O problema é um dataset de entrevistas. Alguns entrevistadores mal intencionados podem ter burlado o sistema e feito -->
<!-- entrevistas em tempos recordes. -->
<!-- 3- Esses entrevistadores mal-intencionados podem estar presentes em qualquer equipe. -->
<!-- 4- A coluna qtde se refere ao numero de entrevistas que foram realizadas por cada entrevistador. -->

<!-- Logo: -->
<!-- Não podemos eliminar o TempoMedio -->
<!-- Não há necessidade de gerar OHE -->
<!-- temos que usar qtde x TempoMedio -->


# Contents {.tabset .tabset-fade .tabset-pills}


## K-Means Analysis

```{r}
# install.packages("FactoMineR")
# install.packages("factoextra")
# install.packages("mltools")
# install.packages("data.table")

library("FactoMineR")
library("factoextra")
library("mltools")
library("caret")
library("data.table")

```


1. Carregar o dataset Usuarios-TempoMedioQuantidade
```{r}
dados <- read.csv(file = "/Users/andrerodrigues/Google Drive/FIAP-MBA 8IA/006 - Modelos de IA e ML/Trabalhos/Trabalho2/data/Usuarios-TempoMedioQuantidade.csv", header = TRUE, sep = ";")
# View(dados)
```


2. Analisando o dataframe
```{r}
sum(is.nan(as.matrix(dados)))
sum(is.na(as.matrix(dados)))
sum(is.infinite(as.matrix(dados)))
ncol(dados)
nrow(dados)

df <- dados
df$NomeUsuario <- NULL
df$Login <- NULL
df$Email <- NULL
df$NomeEquipe <- NULL
# View(df)

```



3. Verificando Outliers
```{r}
boxplot(TempoMedio ~ Quantidade, data=df, main="Boxplot for NomeEquipe vs TempoMedio", cex.axis=0.5)
# View(df)
```

4. Executa o algoritmo k-means:
```{r}
kc <- kmeans(df, 4, nstart = 50)
View(kc)
kc[["cluster"]]
kc[["centers"]]
kc[["size"]]
```


5. Faz a projeção dos dados utilizando as duas primeira dimensões do PCA
```{r}
fviz_cluster(kc, data = df)
```


6. Exemplo do cálculo do elbow point:
```{r}

k.max <- 15
wss <- sapply(1:k.max, 
              function(k){kmeans(df, k, nstart=50,iter.max = 15)$tot.withinss})

plot(1:k.max, wss,
     type="b", pch = 19, frame = FALSE, 
     xlab="Número de clusters K",
     ylab="Soma total da diferença dos quadrados internos dos clusters")
```

*A escolha de agrupar os dados em 4 clusters foi decidida após a análise do elbow point, pois é possível observar que a partir de k=4 temos um decrescimo insignificante da diferença dos quadrados internos dos clusters.* 

```{r}
df$kmeans <- kc[["cluster"]]
View(df)
```


Built with
`r getRversion()`

---

## SOM Analysis

1. Carrega a biblioteca kohonen:
```{r}
# install.packages("kohonen")
library("kohonen")
```


```{r}
set.seed(593)
```


2. Carregar o dataset Usuarios-TempoMedioQuantidade
```{r}
dados_tm <- read.csv(file = "/Users/andrerodrigues/Google Drive/FIAP-MBA 8IA/006 - Modelos de IA e ML/Trabalhos/Trabalho2/data/Usuarios-TempoMedioQuantidade.csv", header = TRUE, sep = ";")
# View(dados_tm)
```



3. Analisando o dataframe
```{r}
sum(is.nan(as.matrix(dados_tm)))
sum(is.na(as.matrix(dados_tm)))
sum(is.infinite(as.matrix(dados_tm)))
ncol(dados_tm)
nrow(dados_tm)
```

4. Removeremos as variáveis dependentes:
```{r}
tm <- dados_tm
tm$NomeUsuario <- NULL
tm$Login <- NULL
tm$Email <- NULL
tm$NomeEquipe <- NULL
# View(tm)
```



5. Faz a escala e normalização dos dados do dataset Usuarios-TempoMedioQuantidade:
```{r}
#Media da coluna - valor do atributo dividido pelo desvio padrão da coluna
df.sc = scale(tm)
# View(df.sc)
ncol(df.sc)
nrow(df.sc)
```


6. Faz o setup da grade de vizinhanca da rede SOM:
```{r}
df.grid = somgrid(xdim = 10, ydim=10, topo="hexagonal")
```




7. Constroi o modelo de rede com os dados do dataset Usuarios-TempoMedioQuantidade , a grade de vizinhanca, numero de iteraces de treinamento e taxa de aprendizado:
```{r}
df.som = som(df.sc, grid=df.grid, rlen=500, alpha=c(0.05,0.01))
```


```{r}
plot(df.som, type="changes")
```




8. Exibe a quantidade de amostras mapeadas por neuronio:
```{r}
plot(df.som, type="count") #Apenas visualiza os neronios com mais dados proximos. Não é o mapa de calor ainda.
```


10. Exibe a medias dos atributos mapeados por neuronio:
```{r}
plot(df.som, type="codes") # Essa visualização é muito importante porque 
# mostra as caracteristicas principais que exercem poder de separação (no caso do iris isso seia a sepal.width).
# Mostra tambem quais são as caracteristicas que menos variam e que, portanto, deveriam ser desprezadas.
```


11. Exibe a relacao de vizinhanca em distancia, algo muito semelhante a matriz U:
```{r}
plot(df.som, type="dist.neighbours")
```



12. Faz uma clusterizaco hierarquica, dos dados ja clusterizados, apenas para facilitar a exibicao:
```{r}
groups = 30
df.hc = cutree(hclust(dist(df.som$codes[[1]][,1:2])), groups)
```

13. Adiciona a fronteira de cada cluster:
```{r}
plot(df.som, type="dist.neighbours")
add.cluster.boundaries(df.som, df.hc)
```

14. Agrupamento
```{r}
plot(df.som, type="codes", bgcol=rainbow(groups)[df.hc])
```


```{r}
View(df.som$codes[[1]])
```


```{r}
clusterneuronio <-df.hc[df.som$unit.classif]
```


```{r}
View(clusterneuronio)
```


```{r}
df$cluster <- clusterneuronio
View(df$cluster)
```

*Conclusão: Cada cluster representa o conjunto de amostras próximas nas características de Tempo Medio e Quantidade de Entrevistas Realizadas.  A aplicação do K-Means facilitou a identificação dos outliers, mais do que o SOM.*

*Em apenas uma amostra, foi  indicado um alto número de entrevistas realizadas com tempo zerado. Essa amostra foi clusterizada isoladamente. Há indicios que houve ou uma má fé do entrevistador, ou um dado de teste perdido no conjunto de dados de producao.* 

*O outro cluster outlier aparece com uma baixa quantidade de entrevistas e um alto tempo médio. A quantidade de amostras neste cluster é igual a 12 e todos pertencem a mesma equipe. O que pode indicar que a equipe está trabalhando com a medida de tempo diferente das demais equipe, ou que são na verdade criteriosos demais na entrevista, o que impactou na quantidade de entrevistas executadas.*


Built with
`r getRversion()`





